{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import Orange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Spodaj razvijemo razred za Gradient Boosting, ki ustreza Orange-ovem objektu za učenje (Learner) in napovedovanje (Model). Implementirali smo tri različne gradiente, ki ustrezajo različnim cenovnim funkcijam (funkcijam napak), katerih vrednost minimiziramo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class GradBoostRLearner(Orange.regression.Learner):\n",
    "    \"\"\"Gradient Boosting for Regression.\"\"\"\n",
    "\n",
    "    def __init__(self, learner, n_estimators=10, epsilon=1e-5, loss=\"squared\"):\n",
    "        super().__init__()\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learner = learner  # base learner\n",
    "        self.name = \"gb \" + self.learner.name + \" \" + loss\n",
    "        self.epsilon = epsilon\n",
    "        losses = {\"huber\": self.grad_huber_loss, \n",
    "                  \"squared\": self.grad_squared_loss, \n",
    "                  \"abs\": self.grad_abs_loss}\n",
    "        self.loss = losses[loss]\n",
    "        \n",
    "    def grad_squared_loss(self, y, f):\n",
    "        \"\"\"Negative gradiant for squared loss.\"\"\"\n",
    "        return y - f\n",
    "    \n",
    "    def grad_abs_loss(self, y, f):\n",
    "        \"\"\"Negative gradient for absolute loss.\"\"\"\n",
    "        return np.sign(y - f)\n",
    "    \n",
    "    def grad_huber_loss(self, y, f, delta=0.5):\n",
    "        \"\"\"Negative gradient for Huber loss.\"\"\"\n",
    "        r0 = y - f\n",
    "        r1 = delta * np.sign(r0)\n",
    "        return np.vstack((r0, r1)).T[np.arange(y.shape[0]), (np.abs(r0)>delta).astype(int)]\n",
    "    \n",
    "    def fit_storage(self, data):\n",
    "        \"\"\"Fitter. Learns a set of models for gradient boosting.\"\"\"\n",
    "        ml = Orange.regression.MeanLearner()\n",
    "        model = ml(data)\n",
    "        y = data.Y\n",
    "        f = model(data)\n",
    "        res = self.loss(y, f)\n",
    "        models = [model]\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            data = Orange.data.Table(data.X, res)\n",
    "            model = self.learner(data)\n",
    "            f += model(data)\n",
    "            res = self.loss(y, f)\n",
    "            models.append(model)\n",
    "        return GradBoostRModel(models)\n",
    "    \n",
    "class GradBoostRModel(Orange.regression.Model):\n",
    "    \"\"\"Classifier for gradient boosting.\"\"\"\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
    "        return sum([m(X) for m in self.models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Testirali bomo na domeni housing (cene hiš v Bostonu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "housing = Orange.data.Table(\"housing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Najbolj nas seveda zanima primerjava z regresijskimi drevesi majhnih globin, kakršne tipično uporabljamo v kombinaciji z gradient boosting-om. Seveda nas zanima tudi, ali lahko s to metodo izboljšamo točnost za kakšnen drugi algoritem učenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml = Orange.regression.MeanLearner()\n",
    "stree = Orange.regression.SimpleTreeLearner(max_depth=3)\n",
    "lr = Orange.regression.LinearRegressionLearner()\n",
    "gb_sq = GradBoostRLearner(stree, n_estimators=50, loss=\"squared\")\n",
    "gb_abs = GradBoostRLearner(stree, n_estimators=50, loss=\"abs\")\n",
    "gb_huber = GradBoostRLearner(stree, n_estimators=50, loss=\"huber\")\n",
    "gb_lr = GradBoostRLearner(lr, n_estimators=50, loss=\"squared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learners = [ml, stree, gb_abs, lr, gb_lr]\n",
    "res = Orange.evaluation.CrossValidation(housing, learners, k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          mean  9.21\n",
      "                   simple tree  4.76\n",
      "            gb simple tree abs  3.68\n",
      "             linear regression  4.85\n",
      "  gb linear regression squared  4.85\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"{:>30} {:5.2f}\".format(m.name, r)\n",
    "                for m, r in zip(learners, Orange.evaluation.RMSE(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Razultati na tej domeni, kažejo na izrazito izboljšavo pri drevesih in na (pričakovano) pomanjkanje kakršnegakoli izboljšanja pri linearni regresiji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

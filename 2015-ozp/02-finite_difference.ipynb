{
 "metadata": {
  "name": "",
  "signature": "sha256:31dba567e245a4502a5519b58cc97f1456727af7d613ca5b352d5d1c279fad6b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Finite Differences Revisited "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Derivatives calculated by hand (or in any other way, which does not generate executable code) should be compared with those obtained using **central differences**. This allows us to check on the correctness of algorithm implementation.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Central differences:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "$$\\frac{\\partial J}{\\partial \\boldsymbol{\\theta}_{i}} = \\frac{J(\\boldsymbol{\\theta}_{i} + \\epsilon) - J(\\boldsymbol{\\theta}_i - \\epsilon)}{2\\epsilon} + O(\\epsilon^2),$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where $J$ is cost function, $\\boldsymbol{\\theta}$ are model parameters and $\\epsilon \\ll 1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A Simple Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we are given a cost function:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "$$ J(\\boldsymbol{\\theta}) = - \\frac{1}{n}(\\sum_{i=1}^{n} y^{(i)} \\log h_\\boldsymbol{\\theta}(x^{(i)}) + (1-y^{(i)}) \\log (1 - h_\\boldsymbol{\\theta}(x^{(i)}))), $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where $n$ is the number of examples, $y^{(i)}$ and $x^{(i)}$ are variables, and $$h_\\boldsymbol{\\theta}(x) = \\frac{1}{1 + \\exp(- \\boldsymbol{\\theta)}^T x}.$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Say, we take the derivatives of $J(\\boldsymbol{\\theta})$ and find the gradient $\\nabla_{\\boldsymbol{\\theta}_i} J(\\boldsymbol{\\theta})$. We implement it in a function ``grad``."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Sidenote: this is softmax regression model without regularization)*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "import Orange"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Our cost function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cost(X, Y, theta):\n",
      "    Theta = theta.reshape(Y.shape[1], X.shape[1])\n",
      "    M = np.dot(X, Theta.T)\n",
      "    P = np.exp(M - np.max(M, axis=1)[:, None])\n",
      "    P /= np.sum(P, axis=1)[:, None]\n",
      "    cost = -np.sum(np.log(P) * Y) / X.shape[0]\n",
      "    return cost"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Our gradient function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ?\n",
      "def grad(X, Y, theta):\n",
      "    Theta = theta.reshape(Y.shape[1], X.shape[1])\n",
      "    M = np.dot(X, Theta.T)\n",
      "    P = np.exp(M - np.max(M, axis=1)[:, None])\n",
      "    P /= np.sum(P, axis=1)[:, None]\n",
      "    grad = np.dot(X.T, P - Y).T / X.shape[0]\n",
      "    return grad.ravel()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Central differences "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def numerical_grad(f, params, epsilon):\n",
      "    num_grad = np.zeros_like(theta)\n",
      "    perturb = np.zeros_like(params)\n",
      "    for i in range(params.size):\n",
      "        perturb[i] = epsilon\n",
      "        j1 = f(params + perturb)\n",
      "        j2 = f(params - perturb)\n",
      "        num_grad[i] = (j1 - j2) / (2. * epsilon)\n",
      "        perturb[i] = 0\n",
      "    return num_grad"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Let's get some data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = Orange.data.Table('iris')\n",
      "X = data.X\n",
      "Y = np.eye(3)[data.Y.astype(int)]  \n",
      "theta = np.random.randn(3 * 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Compare derivatives returned by ``grad`` function with those obtained by central differences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compare analytical gradient with gradient obtained by numerical differentiation \n",
      "ag = grad(X, Y, theta)\n",
      "ng = numerical_grad(lambda params: cost(X, Y, params), theta, 1e-4)\n",
      "print(np.sum((ag - ng)**2))\n",
      "ag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.8849503346e-22\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([ 4.17463807,  1.91465189,  3.27064945,  1.11732824, -1.97864123,\n",
        "       -0.92332007, -1.41998535, -0.44199582, -2.19599684, -0.99133181,\n",
        "       -1.8506641 , -0.67533241])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ng"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([ 4.17463807,  1.91465189,  3.27064945,  1.11732824, -1.97864123,\n",
        "       -0.92332007, -1.41998535, -0.44199582, -2.19599684, -0.99133181,\n",
        "       -1.8506641 , -0.67533241])"
       ]
      }
     ],
     "prompt_number": 42
    }
   ],
   "metadata": {}
  }
 ]
}
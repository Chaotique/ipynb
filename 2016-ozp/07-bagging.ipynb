{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razvijemo razred za tehniko bagging, oziroma [bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating), ki lahko izboljša stabilnost in točno napovednih metod, katerih struktura modela je lahko precej odvisna od vzorca podatkov. To je, katerih struktura zgrajenega modela se pri manjših spremembah v učnih podatkih lahko precej spremeni. Primer take metode so klasifikacijska in regresijska drevesa, lahko pa bagging pomaga tudi kakšnim drugim tehnikam. Bagging si ogledamo tudi kot primer ansamblov, torej metod, ki temeljijo na gradnji množice modelov in potem s povprečenjem ali glasovanjem predlagajo vrednost razreda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprej preberemo podatke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Orange\n",
    "from Orange.preprocess.preprocess import Preprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RemoveConstant(Preprocess):\n",
    "    def __call__(self, data):\n",
    "        oks = np.min(data.X, axis=0) != np.max(data.X, axis=0)\n",
    "        atts = [a for a, ok in zip(data.domain.attributes, oks) if ok]\n",
    "        domain = Orange.data.Domain(atts, data.domain.class_vars)\n",
    "        return Orange.data.Table(domain, data)\n",
    "\n",
    "rc = RemoveConstant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 523)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = Orange.data.Table(\"digits-sample.csv\")\n",
    "orig = Orange.data.Table(\"seven-nine.csv\")\n",
    "# orig = Orange.data.Table(\"promoters\")\n",
    "# orig = Orange.data.Table(\"all-1000.csv\")\n",
    "data = rc(orig)\n",
    "len(data), len(data.domain.attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na podatkih ovrednotimo nekaj osnovnih klasifikatorjev. Uporabimo klasifikacijska drevesa in logistično regresijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = Orange.classification.SimpleTreeLearner()\n",
    "lr = Orange.classification.LogisticRegressionLearner()\n",
    "maj = Orange.classification.MajorityLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learners = [tree, lr, maj]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         simple tree  0.89\n",
      "              logreg  0.93\n",
      "            majority  0.50\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drevesa se ne obneseje najbolje, logistična regresija je boljša."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orange-ov razred za Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orange-ova shema za napovedne modele vedno vsebuje Learner in Model, torej, razred, ki je namenjen učenju in razred, ki je namenjen napovedovanju. Uporabimo razred in ne funkcije: iz njih izvedeni objekti si bodo morali zapomniti nekatere nastavitve in parametre, potem pa jih bomo uporabili pri učenju in napovedovanju. Razred za učenje (BaggedLearner) si bo moral zapomniti algoritem učenja, ki ga bomo uporabili na k vzorcih podatkov, razred za napovedovanje (BaggedModel) pa bomo inicializirali s seznamom k naučenih modelov.\n",
    "\n",
    "BaggedLearner implementira vzorčenje po metodi stremena (angl. boosting). Po inicializaciji objekt kličemo s podatki. Klic nam vrne regresor, BaggedModel, ki hrani naučene modele. Ob klicu regresorja ta uporabi napovedne modele in izračuna povprečje napovedi, ki jih ti vrnejo. BaggedModel lahko kličemo z enim samim primerom, lahko pa mu tudi podtaknemo tabelo primerov. Pri slednjem nam bo klic tega objekta vrnil vektor napovedi.\n",
    "\n",
    "Bagging bomo implementirali za regresijo, torej privzeli, da nam napovedni modeli vračajo realne vrednost. Pri klasifikaciji bi implementacija bila rahlo kompleksnejša, saj nam v Orange-u klasifikatorji lahko vračajo razrede ali pa njihove verjetnosti, odvisno od parametra, ki ga podamo pri klicu klasifikatorja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BaggedLearner(Orange.classification.Learner):\n",
    "    \"\"\"Bootstrap aggregating learner.\"\"\"\n",
    "    def __init__(self, learner, k=3):\n",
    "        super().__init__()\n",
    "        self.k = k # number of bootstrap samples and corresponding models\n",
    "        self.learner = learner # base learner\n",
    "        self.name = \"bagged \" + self.learner.name\n",
    "    \n",
    "    def fit_storage(self, data):\n",
    "        \"\"\"Return a bagged model inferred from the training set.\"\"\"\n",
    "        models = []\n",
    "        for epoch in range(self.k):\n",
    "            indices = np.random.randint(len(data), size=len(data))  # sample indices\n",
    "            models.append(self.learner(data[indices]))  # model inference from a sample\n",
    "        model = BaggedModel(data.domain, models)  # return a predictor that remembers a list of models\n",
    "        model.name = self.name\n",
    "        return model\n",
    "\n",
    "class BaggedModel(Orange.classification.Model):\n",
    "    \"\"\"Bootstrap aggregating classifier.\"\"\"\n",
    "    def __init__(self, domain, models):\n",
    "        super().__init__(domain)\n",
    "        self.models = models  # a list of predictors\n",
    "    \n",
    "    def predict_storage(self, data, ret=Orange.classification.Model.Value):\n",
    "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
    "        p = np.mean([m(data, 1) for m in self.models], axis=0)\n",
    "        return p / p.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uporabimo bagging nad drevesi in linearno regresijo. Točnost napovedi ocenimo s prečnim preverjanjem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_tree = BaggedLearner(tree, k=50)\n",
    "bag_lr = BaggedLearner(lr, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = bag_tree(data)\n",
    "bt(data[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ],\n",
       "       [ 0.03,  0.97],\n",
       "       [ 1.  ,  0.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt(data[0:3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learners = [tree, bag_tree, lr, bag_lr]\n",
    "learners = [tree, bag_tree]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         simple tree  0.89\n",
      "  bagged simple tree  0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging z drevesi se med zgornjimi dobro obnese. Zanimivo. Izboljšanje logistične regresije pa nam po drugi strani ni uspelo. Zakaj? Drevesa zgrajena na vzorčenih podatki se dejansko bistveno razlikujejo med sabo (kako bi to preverili?), razlike med dobljenimi modeli logistične regresije pa so majhne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ponaključenje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sledi finta. V angleščini bi se ji reklo *randomization*. Namreč, radi bi izboljšali tudi napovedi linearne regresije. In pri tem uporabili ansamble, oziroma niz napovednih modelov. Ampak, kot že rečeno, ti napovedni modeli se morajo med sabo razlikovati, sicer jih z baggingom ne bomo prav dosti izboljšali. Namesto vzorčenja podatkov bomo raje vzorčili atribute, in regresorje, na primer linearno regresiju, gradili na celotnih podatkih, ki pa bodo vsebovali samo manjši delež (p) originalnih atributov. Pričakujemo, da se bodo modeli linearne regresije, ki bodo zgrajeni na različnih domenah (različnih naborih atributov) med seboj dovolj razlikovali, da bo njihov ansambel uspešen.\n",
    "\n",
    "Spodaj implementiramo samo razred za učenje (RandomizedLearner), za napovedovanje s povprečenjem napovedi večih modelov pa recikliramo kar BaggedModel. RandomizedLearner je podobno preprost kot BaggedLearner. Za izbor atributov oziroma konstrukcijo nove tabele z podmnožico originalnih atributov smo uporabili kar Orange-ov SelectRandomFeatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomizedLearner(Orange.classification.Learner):\n",
    "    \"\"\"Ensamble learning through randomization of data domain.\"\"\"\n",
    "    def __init__(self, learner, k=3, p=0.5):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.learner = learner\n",
    "        self.name = \"rand \" + self.learner.name\n",
    "        # a function to be used for random attribute subset selection\n",
    "        self.selector = Orange.preprocess.fss.SelectRandomFeatures(k=p)\n",
    "    \n",
    "    def fit_storage(self, data):\n",
    "        \"\"\"Returns a bagged model with randomized regressors.\"\"\"\n",
    "        models = []\n",
    "        for epoch in range(self.k):\n",
    "            sample = self.selector(data) # data with a subset of attributes\n",
    "            models.append(self.learner(sample))\n",
    "        model = BaggedModel(data.domain, models)\n",
    "        model.name = self.name\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd_lr = RandomizedLearner(lr, k=50, p=0.2)\n",
    "learners = [maj, lr, rnd_lr]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            majority  0.50\n",
      "              logreg  0.93\n",
      "         rand logreg  0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tole deluje še kar ok, oziroma logistične regresije vsaj ne pokvari. Na kakšni drugi domeni bi lahko tudi pomagalo, oziroma se zna zgoditi, da ima ansambel ponaključenih logističnih regresij večjo točnost od logistične regresije same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naključni gozd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasičen, ali morda celo najbolj tipičen primer ponaklučenja (randomizacije) so naključni gozdovi (angl. random forest). Tu je bil narejen poseg v algoritem učenja dreves, ki ob gradnji drevesa ne uporabi vač za razcep množice primerov najprimernejšega atributa, ampak atribut za razcep naključno izbere iz množice najprimernejši. Poleg uporabljenega vzorčanje z metodo stremena to še dodatno poskrbi za raznolikost dreves v gozdu.\n",
    "\n",
    "Spodaj smo kot primer uporabili kar SimpleRandomForestLearner, ki je hitra C-jevska implementacija naključnih gozdov. Dokler ni scikit-learn odpravil nekaj bugov in pospešil svojo implementacijo, je bil SimpleRandomForestLearner morda najhitrejša implementacija naključnega gozda z vmesnikom v Pythonu. Orange zawrapa sicer tudi implementacijo iz sklearn-a (RandomForestLearner), ki pa meni, vsaj na tej domeni, včasih daje malce slabše rezultate od Orange-ovega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skl_forest = Orange.classification.RandomForestLearner(n_estimators=50)\n",
    "skl_forest.name = \"skl forest\"\n",
    "forest = Orange.classification.SimpleRandomForestLearner(n_estimators=50)\n",
    "learners = [tree, forest, skl_forest]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         simple tree  0.89\n",
      "     simple rf class  0.93\n",
      "          skl forest  0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4], [5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33333333,  0.66666667],\n",
       "       [ 0.42857143,  0.57142857],\n",
       "       [ 0.45454545,  0.54545455]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/a.sum(axis=1, keepdims=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ovojnica za binarne klasifikatorje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z ovojnico (wrapperjem) za binarne klasifikatorje želimo te uporabiti pri učenju na večrazrednih problemih. Torej na podatkih, kjer je število razredov lahko tudi večje od dva. Spodnjo ovojnico smo razvili za Orange, uporabimo pa jo lahko na kakršnemkoli učnem algoritmu Oranga, tudi na teh, ki so sicer večrazredni. Postopek, ki smo ga implementirali, je podoben postopku [one-vs-rest](http://en.wikipedia.org/wiki/Multiclass_classification), a s trikom. Da bi se izognili razredno neuravnoteženim učnim primerom, za vsak binarni klasifikator in primere, ki so uvrščeni v njegov ciljni razred, vzorčimo enako število učnih primerov iz drugih razredov. V spodnji implementaciji je še ena razlika s splošnim postopkom one-vs-rest. Napovedujemo namreč verjetnosti. Za vsak razred s klasifikatorjem za ta razred ocenimo verjetnost razreda in ga shranimo v seznam verjetnosti. Na koncu postopka seznam normaliziramo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Orange\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preberemo podatke o rožicah in preverimo, kakšno število razrednih vrednosti ima ta nabor podatkov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Orange.data.Table(\"iris\")\n",
    "len(data.domain.class_var.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learnerji v Orangu so objekti. Ko jim podamo podatke, nam vrnejo klasifikator, ki je prav tako objekt. Ta lahko sprejme en sam primer ali pa množico primerov. Klasifikatorji kot rezultat lahko vračajo razred (vrednost diskretne spremenljivke) ali verjetnosti razredov. Ker lahko klasifikatorje kličemo s seznamom primerov, je pri vračanju verjetnosti objekt, ki ga vrnejo, matrika. Oglejmo si to na spodnjem primeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = Orange.classification.LogisticRegressionLearner()\n",
    "tree = Orange.classification.SimpleTreeLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value('iris', Iris-setosa)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = logreg(data)\n",
    "classifier(data[0]) # klasificiramo en primer, klasifikator vrne razred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.79681649e-01,   1.20307538e-01,   1.08131372e-05]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(data[0], 1) # od klasifikatorja zahtevamo verjetnost razredov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.79681649e-01,   1.20307538e-01,   1.08131372e-05],\n",
       "       [  7.99706325e-01,   2.00263292e-01,   3.03825365e-05],\n",
       "       [  8.53796795e-01,   1.46177302e-01,   2.59031285e-05],\n",
       "       [  8.25383127e-01,   1.74558937e-01,   5.79356669e-05],\n",
       "       [  8.97323628e-01,   1.02665167e-01,   1.12050036e-05]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(data[0:5], 1) # verjetnosti za prvih pet primerov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sledi trik, ki ga bomo potrebovali pri implementaciji naše ovojnice: iz matrike napovedanih verjetnosti bi radi pridobili verjetnosti (samo) za i-ti razred. Želeli bi ga imeti kot slopični vektor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12030754],\n",
       "       [ 0.20026329],\n",
       "       [ 0.1461773 ],\n",
       "       [ 0.17455894],\n",
       "       [ 0.10266517]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "classifier(data[0:5], 1)[:, [i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ovojnica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj pa k naši ovojnici. Ker se bo ta obnašala kot Orange-ov learner, jo izvedemo iz tega razreda. V inicializacijskem delu si zapomnemo binarni learner, ki ga bo ovojnica uporabila za učenje. Potem implementiramo funkcijo fit_storage, ki je namenjena učenju, ko podatke podamo v obliki Orange-ove tabele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MulticlassLearner(Orange.classification.Learner):\n",
    "    \"\"\"Wraps binary learner into a multi-class learner\"\"\"\n",
    "    def __init__(self, learner):\n",
    "        super().__init__()\n",
    "        self.learner = learner\n",
    "        self.name = \"mc \" + learner.name\n",
    "    \n",
    "    def fit_storage(self, data):\n",
    "        classifiers = []\n",
    "        for i in range(len(data.domain.class_var.values)):\n",
    "            # priprava podatkov, najprej primeri z razredom i\n",
    "            X1 = data.X[data.Y == i]\n",
    "            y1 = np.array([0] * X1.shape[0]) # cilji razred ima indeks 0\n",
    "\n",
    "            # sledi vzorec primerov z razredom, ki je drugačen od i\n",
    "            ind = np.arange(len(data))[data.Y != i]\n",
    "            np.random.shuffle(ind)\n",
    "            X0 = data.X[ind[:X1.shape[0]]]\n",
    "            y0 = np.array([1] * X0.shape[0])\n",
    "            \n",
    "            # oblikujemo dvovrednostno domeno\n",
    "            domain = Orange.data.Domain(data.domain.attributes, \n",
    "                                        Orange.data.DiscreteVariable(\"class\", values=[\"T\", \"F\"]))\n",
    "            # podatke združimo v tabelo\n",
    "            xy = Orange.data.Table(domain, np.vstack((X1, X0)), np.hstack((y1, y0)))\n",
    "            # tabelo podamo binarnemu učnemu algoritmu in shranimo vrnjeni klasifikator v seznam\n",
    "            classifiers.append(self.learner(xy))\n",
    "        # seznam klasifikatorjev podamo objektu, ki bo primere klasificiral\n",
    "        mc = MulticlassModel(data.domain, classifiers)\n",
    "        mc.name = self.name\n",
    "        return mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razred za klasifikacijo si ob inicializaciji zapomni seznam klasifikatorjev za posamezni razred. Implementirati mora funkcijo za napovedovanje. V naši kodi smo implementirali samo del, ki vrača verjetnosti. Tu za vsak model m pridobimo verjetnosti razredov (dvostolpična matrika) s klicem m(data, 1). Iz te matrike nato izberemo samo prvi stolpec z m(data, 1)[:, [0]]. Te stolpce, ki nam za dane testne podatke predstavljajo verjetnosti k razredov, združimo s funkcijo hstack. Dobimo matriko, kjer so stolpci ocene verjetnosti razredov, vrstice pa ustrezajo posameznim primerom v testni množici. Verjetnosti za posamezne primere moramo še normalizirati. To storimo tako, da oblikujemo vektor z vsotami po vrsticah z ps.sum(axis=1), ta vrstični vektor pa preoblikujemo v stolpčni z [:, None]. Nato vrnemo normalizirane ocene verjetnosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MulticlassModel(Orange.classification.Model):\n",
    "    \"\"\"Multi-class classifier based on a set of binary classifiers.\"\"\"\n",
    "    def __init__(self, domain, models):\n",
    "        super().__init__(domain)\n",
    "        self.models = models # a list of predictors\n",
    "    \n",
    "    def predict(self, data, ret=1):\n",
    "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
    "        ps = np.hstack([m(data, 1)[:, [0]] for m in self.models])\n",
    "        sums = ps.sum(axis=1)[:, None]\n",
    "        return ps / sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sledi primer uporabe našega novega učnega postopka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dela?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = MulticlassLearner(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = mc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.52572914e-01,   1.47350436e-01,   7.66505579e-05],\n",
       "       [  8.20845929e-01,   1.78831492e-01,   3.22579286e-04],\n",
       "       [  7.55522357e-01,   2.44249363e-01,   2.28279781e-04],\n",
       "       [  8.03001351e-01,   1.96720004e-01,   2.78645648e-04],\n",
       "       [  8.96832364e-01,   1.03151039e-01,   1.65970916e-05]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl(data[10:15], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl(data[10:15], 1).sum(axis=1) # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dela! Čas je za pravi test. Namreč, z zgornjim smo se malo namučili po Orange-ovsko zato, da bi lahko naš učni postopek uporabljali tako, kot vse ostale učne algoritme Orange. Torej tudi v prečnem preverjanju. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.965,  0.965])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj = Orange.classification.MajorityLearner()\n",
    "lr = Orange.classification.LogisticRegressionLearner()\n",
    "mc_lr = MulticlassLearner(lr)\n",
    "mc_tree = MulticlassLearner(tree)\n",
    "res = Orange.evaluation.CrossValidation(data, [mc_lr, lr])\n",
    "Orange.evaluation.AUC(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zgoraj smo za mero točnosti uporabili AUC, [površino pod krivuljo ROC](http://en.wikipedia.org/wiki/Receiver_operating_characteristic). O tej meri bo na predavanjih še govora. Pri izzivu Otto Group na [Kagglu](http://www.kaggle.com) pa kot mero uspešnosti uporabljajo [logloss](https://www.kaggle.com/wiki/LogarithmicLoss). Poskus implementacije te (preveri, če ta res daje prave vrednosti!) je spodaj. Spodnja funkcija seveda deluje nad objektom, ki ga vračajo Orange-ovi razredi za testiranje učnih algoritmov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logloss(res):\n",
    "    ll = []\n",
    "    for i in range(res.probabilities.shape[0]):\n",
    "        # x je vektor verjetnosti, ki smo jih napovedali dejanskemu razredu\n",
    "        x = np.array([v[i] for v, i in zip(res.probabilities[i], res.actual.astype(int))])\n",
    "        ll.append(-sum(np.log(x))/len(x))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39854952412347, 0.32028596555193267]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

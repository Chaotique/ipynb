{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razvijemo razred za tehniko bagging, oziroma [bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating), ki lahko izboljša stabilnost in točno napovednih metod, katerih struktura modela je lahko precej odvisna od vzorca podatkov. To je, katerih struktura zgrajenega modela se pri manjših spremembah v učnih podatkih lahko precej spremeni. Primer take metode so klasifikacijska in regresijska drevesa, lahko pa bagging pomaga tudi kakšnim drugim tehnikam. Bagging si ogledamo tudi kot primer ansamblov, torej metod, ki temeljijo na gradnji množice modelov in potem s povprečenjem ali glasovanjem predlagajo vrednost razreda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprej preberemo podatke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Orange\n",
    "from Orange.preprocess.preprocess import Preprocess\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RemoveConstant(Preprocess):\n",
    "    def __call__(self, data):\n",
    "        oks = np.min(data.X, axis=0) != np.max(data.X, axis=0)\n",
    "        atts = [a for a, ok in zip(data.domain.attributes, oks) if ok]\n",
    "        domain = Orange.data.Domain(atts, data.domain.class_vars)\n",
    "        return Orange.data.Table(domain, data)\n",
    "\n",
    "rc = RemoveConstant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 1000, 1000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = Orange.data.Table(\"data/smoking-small.tab\")\n",
    "data = rc(orig)\n",
    "len(data), len(orig.domain.attributes), len(data.domain.attributes), len(data.domain.class_var.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na podatkih ovrednotimo nekaj osnovnih klasifikatorjev. Uporabimo klasifikacijska drevesa in k-najbližjih sosedov, za vsak slučaj pa preverjamo še napovedovanje z večinskim razredom, pri katerem bi moral biti AUC enak 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maj = Orange.classification.MajorityLearner()\n",
    "tree = Orange.classification.TreeLearner()\n",
    "knn = Orange.classification.KNNLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learners = [maj, tree, knn]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            majority  0.50\n",
      "                tree  0.72\n",
      "                 knn  0.77\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drevesa se ne obneseje najbolje, nekoliko boljši so najbližji sosedje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orange-ov razred za Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orange-ova shema za napovedne modele vedno vsebuje Learner in Model, torej, razred, ki je namenjen učenju in razred, ki je namenjen napovedovanju. Uporabimo razred in ne funkcije: iz njih izvedeni objekti si bodo morali zapomniti nekatere nastavitve in parametre, potem pa jih bomo uporabili pri učenju in napovedovanju. Razred za učenje (BaggedLearner) si bo moral zapomniti algoritem učenja, ki ga bomo uporabili na k vzorcih podatkov, razred za napovedovanje (BaggedModel) pa bomo inicializirali s seznamom k naučenih modelov.\n",
    "\n",
    "BaggedLearner implementira vzorčenje po metodi stremena (angl. boosting). Po inicializaciji objekt kličemo s podatki. Klic nam vrne regresor, BaggedModel, ki hrani naučene modele. Ob klicu regresorja ta uporabi napovedne modele in izračuna povprečje napovedi, ki jih ti vrnejo. BaggedModel lahko kličemo z enim samim primerom, lahko pa mu tudi podtaknemo tabelo primerov. Pri slednjem nam bo klic tega objekta vrnil vektor napovedi.\n",
    "\n",
    "Bagging bomo implementirali za regresijo, torej privzeli, da nam napovedni modeli vračajo realne vrednost. Pri klasifikaciji bi implementacija bila rahlo kompleksnejša, saj nam v Orange-u klasifikatorji lahko vračajo razrede ali pa njihove verjetnosti, odvisno od parametra, ki ga podamo pri klicu klasifikatorja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BaggedLearner(Orange.classification.Learner):\n",
    "    \"\"\"Bootstrap aggregating learner.\"\"\"\n",
    "    def __init__(self, learner, k=3):\n",
    "        super().__init__()\n",
    "        self.k = k # number of bootstrap samples and corresponding models\n",
    "        self.learner = learner # base learner\n",
    "        self.name = \"bagged \" + self.learner.name\n",
    "    \n",
    "    def fit_storage(self, data):\n",
    "        \"\"\"Return a bagged model inferred from the training set.\"\"\"\n",
    "        models = []\n",
    "        for epoch in range(self.k):\n",
    "            indices = np.random.randint(len(data), size=len(data))  # sample indices\n",
    "            models.append(self.learner(data[indices]))  # model inference from a sample\n",
    "        model = BaggedModel(data.domain, models)  # return a predictor that remembers a list of models\n",
    "        model.name = self.name\n",
    "        return model\n",
    "\n",
    "class BaggedModel(Orange.classification.Model):\n",
    "    \"\"\"Bootstrap aggregating classifier.\"\"\"\n",
    "    def __init__(self, domain, models):\n",
    "        super().__init__(domain)\n",
    "        self.models = models  # a list of predictors\n",
    "    \n",
    "    def predict_storage(self, data, ret=Orange.classification.Model.Value):\n",
    "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
    "        p = np.mean([m(data, 1) for m in self.models], axis=0)\n",
    "        return p / p.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uporabimo bagging nad drevesi in linearno regresijo. Točnost napovedi ocenimo s prečnim preverjanjem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_tree = BaggedLearner(tree, k=10)\n",
    "bag_knn = BaggedLearner(knn, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00529617,  0.99470383]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = bag_tree(data)\n",
    "bt(data[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00529617,  0.99470383],\n",
       "       [ 0.00529617,  0.99470383],\n",
       "       [ 0.10285714,  0.89714286]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt(data[0:3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learners = [tree, bag_tree, knn, bag_knn]\n",
    "# learners = [tree, bag_tree]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tree  0.72\n",
      "         bagged tree  0.87\n",
      "                 knn  0.77\n",
      "          bagged knn  0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging z drevesi se med zgornjimi dobro obnese. Izboljšanje najbližjih sosedov pa nam po drugi strani ni uspelo. Zakaj? Drevesa zgrajena na vzorčenih podatki se dejansko bistveno razlikujejo med sabo (kako bi to preverili?), razlike med dobljenimi modeli najbližjih sosedov pa so majhne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ponaključenje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sledi finta. V angleščini bi se ji reklo *randomization*. Namreč, radi bi izboljšali tudi napovedi najbližjih sosedov. In pri tem uporabili ansamble, oziroma niz napovednih modelov. Ampak, kot že rečeno, ti napovedni modeli se morajo med sabo razlikovati, sicer nam bagging prav dosti ne bo pomagal. Da bi modeli tudi pri stabilnih klasifikatorjih, kot so najbližji sosedi, med sabo bili čimbolj različni, lahko namesto vzorčenja podatkov vzorčimo atribute.\n",
    "\n",
    "Spodaj implementiramo samo razred za učenje (RandomizedLearner), ki gradimo modele na vzorčenih množicah atributov, za napovedovanje s povprečenjem napovedi večih modelov pa recikliramo kar BaggedModel. RandomizedLearner je podobno preprost kot BaggedLearner. Za izbor atributov oziroma konstrukcijo nove tabele z podmnožico originalnih atributov smo uporabili kar Orange-ov SelectRandomFeatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomizedLearner(Orange.classification.Learner):\n",
    "    \"\"\"Ensamble learning through randomization of data domain.\"\"\"\n",
    "    def __init__(self, learner, k=3, p=0.5):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.learner = learner\n",
    "        self.name = \"rand \" + self.learner.name\n",
    "        # a function to be used for random attribute subset selection\n",
    "        self.selector = Orange.preprocess.fss.SelectRandomFeatures(k=p)\n",
    "    \n",
    "    def fit_storage(self, data):\n",
    "        \"\"\"Returns a bagged model with randomized regressors.\"\"\"\n",
    "        models = []\n",
    "        for epoch in range(self.k):\n",
    "            sample = self.selector(data) # data with a subset of attributes\n",
    "            models.append(self.learner(sample))\n",
    "        model = BaggedModel(data.domain, models)\n",
    "        model.name = self.name\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd_knn = RandomizedLearner(knn, k=10, p=0.2)\n",
    "learners = [maj, knn, rnd_knn]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            majority  0.50\n",
      "                 knn  0.77\n",
      "            rand knn  0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tole deluje še kar ok, oziroma logistične regresije vsaj ne pokvari. Na kakšni drugi domeni bi lahko tudi pomagalo, oziroma se zna zgoditi, da ima ansambel ponaključenih logističnih regresij večjo točnost od logistične regresije same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naključni gozd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasičen, ali morda celo najbolj tipičen primer ponaklučenja (randomizacije) so naključni gozdovi (angl. random forest). Tu je bil narejen poseg v algoritem učenja dreves, ki ob gradnji drevesa ne uporabi vač za razcep množice primerov najprimernejšega atributa, ampak atribut za razcep naključno izbere iz množice najprimernejši. Poleg uporabljenega vzorčanje z metodo stremena to še dodatno poskrbi za raznolikost dreves v gozdu.\n",
    "\n",
    "Spodaj smo kot primer uporabili kar SimpleRandomForestLearner, ki je hitra C-jevska implementacija naključnih gozdov. Dokler ni scikit-learn odpravil nekaj bugov in pospešil svojo implementacijo, je bil SimpleRandomForestLearner morda najhitrejša implementacija naključnega gozda z vmesnikom v Pythonu. Orange zawrapa sicer tudi implementacijo iz sklearn-a (RandomForestLearner), ki pa meni, vsaj na tej domeni, včasih daje malce slabše rezultate od Orange-ovega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = Orange.classification.RandomForestLearner(n_estimators=10)\n",
    "forest.name = \"skl forest\"\n",
    "learners = [tree, forest]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tree  0.72\n",
      "          skl forest  0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Še boljše rezultate dobimo, če dvignemo število dreves na, recimo 500. Tipično se pri naključnih gozdovih gradi recimo 500 ali 1000 dreves, večje število dreves od teh pa nam navadno ne pomaga kaj dosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest.params['n_estimators'] = 500\n",
    "learners = [tree, forest]\n",
    "res = Orange.evaluation.CrossValidation(data, learners, k=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tree  0.72\n",
      "          skl forest  0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.AUC(res))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

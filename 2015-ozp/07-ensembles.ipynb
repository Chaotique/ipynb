{
 "metadata": {
  "name": "",
  "signature": "sha256:784b3e81b5b7bed86bb7dbccacbc8d1651daf9b2dc7288be9e2b04c13dea17fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Bagging"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Najprej preberemo podatke."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Orange\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = Orange.data.Table(\"imp.tab\")\n",
      "selector = Orange.preprocess.fss.SelectRandomFeatures(k=0.2)\n",
      "data = selector(data)\n",
      "# data = Orange.data.Table(\"housing\")\n",
      "print(data.domain.class_var, len(data), len(data.domain.attributes))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INTENSITY/STRENGTH 280 973\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Na podatkih ovrednotimo nekaj osnovnih regresorjev. Uporabimo regresijska drevesa in linearno regresijo. Za ob\u010dutek dodamo \u0161e elastic net, ki bi naj bil najbolj\u0161i."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = Orange.classification.SimpleTreeLearner()\n",
      "lr = Orange.regression.RidgeRegressionLearner()\n",
      "mean = Orange.regression.MeanLearner()\n",
      "elastic = Orange.regression.ElasticNetLearner()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = Orange.evaluation.CrossValidation(data, [tree, lr, mean], k=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Orange.evaluation.RMSE(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([ 24.93456516,  40.25960294,  24.75862269])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drevesa in linearna regresija z L2 regulatrizacijo se obneseta slabo, celo slab\u0161e od napovedi z srednjo vrednostjo."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Orange-ov razred za Bagging"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Orange-ova shema za napovedne modele vedno vsebuje Learner in Model, torej, razred, ki je namenjen u\u010denju in razred, ki je namenjen napovedovanju. Uporabimo razred in ne funkcije: iz njih izvedeni objekti si bodo morali zapomniti nekatere nastavitve in parametre, potem pa jih bomo uporabili pri u\u010denju in napovedovanju. Razred za u\u010denje (BaggedLearner) si bo moral zapomniti algoritem u\u010denja, ki ga bomo uporabili na k vzorcih podatkov, razred za napovedovanje (BaggedModel) pa bomo inicializirali s seznamom k nau\u010denih modelov.\n",
      "\n",
      "BaggedLearner implementira vzor\u010denje po metodi stremena (angl. boosting). Po inicializaciji objekt kli\u010demo s podatki. Klic nam vrne regresor, BaggedModel, ki hrani nau\u010dene modele. Ob klicu regresorja ta uporabi napovedne modele in izra\u010duna povpre\u010dje napovedi, ki jih ti vrnejo. BaggedModel lahko kli\u010demo z enim samim primerom, lahko pa mu tudi podtaknemo tabelo primerov. Pri slednjem nam bo klic tega objekta vrnil vektor napovedi.\n",
      "\n",
      "Bagging bomo implementirali za regresijo, torej privzeli, da nam napovedni modeli vra\u010dajo realne vrednost. Pri klasifikaciji bi implementacija bila rahlo kompleksnej\u0161a, saj nam v Orange-u klasifikatorji lahko vra\u010dajo razrede ali pa njihove verjetnosti, odvisno od parametra, ki ga podamo pri klicu klasifikatorja."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BaggedLearner(Orange.classification.Learner):\n",
      "    \"\"\"Bootstrap aggregating learner.\"\"\"\n",
      "    def __init__(self, learner, k=3):\n",
      "        super().__init__()\n",
      "        self.k = k # number of bootstrap samples and corresponding models\n",
      "        self.learner = learner # base learner\n",
      "        self.name = \"bagged \" + self.learner.name\n",
      "    \n",
      "    def fit_storage(self, data):\n",
      "        \"\"\"Return a bagged model inferred from the training set.\"\"\"\n",
      "        models = []\n",
      "        for epoch in range(self.k):\n",
      "            indices = np.random.randint(len(data), size=len(data)) # sample indices\n",
      "            models.append(self.learner(data[indices])) # model inference from a sample\n",
      "        model = BaggedModel(data.domain, models) # return a predictor that remembers a list of models\n",
      "        model.name = self.name\n",
      "        return model\n",
      "\n",
      "class BaggedModel(Orange.classification.Model):\n",
      "    \"\"\"Bootstrap aggregating classifier.\"\"\"\n",
      "    def __init__(self, domain, models):\n",
      "        super().__init__(domain)\n",
      "        self.models = models  # a list of predictors\n",
      "    \n",
      "    def predict_storage(self, data, ret=Orange.classification.Model.Value):\n",
      "        \"\"\"Given a data instance or table of data instances returns predicted class.\"\"\"\n",
      "        return np.mean([m(data) for m in self.models], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Uporabimo bagging nad drevesi in linearno regresijo. To\u010dnost napovedi ocenimo s pre\u010dnim preverjanjem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bag_tree = BaggedLearner(tree, k=50)\n",
      "bag_lr = BaggedLearner(lr, k=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "learners = [mean, tree, lr, elastic, bag_tree, bag_lr]\n",
      "res = Orange.evaluation.CrossValidation(data, learners, k=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.RMSE(res))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                mean 24.73\n",
        "         simple tree 23.78\n",
        "               ridge 39.68\n",
        "             elastic 19.97\n",
        "  bagged simple tree 18.76\n",
        "        bagged ridge 26.69\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bagging z drevesi se med zgornjimi najbolje obnese. Zanimivo. Saj na tej domeni drevo samo zase ne izbolj\u0161a niti napovedi s povpre\u010dno vrednostjo. Bagging sicer izbolj\u0161a tudi rezulate linearne regresije, a so ti dale\u010d od bagging z drevesi in enako slabi, kot je napoved s povpre\u010dno vrednostjo razreda v u\u010dnih podatkih. Zakaj? Drevesa zgrajena na vzor\u010denih podatki se dejansko bistveno razlikujejo med sabo (kako bi to preverili?), razlike med dobljenimi linearnimi regresorji pa so majhne."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Randomization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sledi finta. Namre\u010d, radi bi izbolj\u0161ali tudi napovedi linearne regresije. In pri tem uporabili ansamble, oziroma niz napovednih modelov. Ampak, kot \u017ee re\u010deno, ti napovedni modeli se morajo med sabo razlikovati, sicer jih z baggingom ne bomo prav dosti izbolj\u0161ali. Namesto vzor\u010denja podatkov bomo raje vzor\u010dili atribute, in regresorje, na primer linearno regresiju, gradili na celotnih podatkih, ki pa bodo vsebovali samo manj\u0161i dele\u017e (p) originalnih atributov. Pri\u010dakujemo, da se bodo modeli linearne regresije, ki bodo zgrajeni na razli\u010dnih domenah (razli\u010dnih naborih atributov) med seboj dovolj razlikovali, da bo njihov ansambel uspe\u0161en.\n",
      "\n",
      "Spodaj implementiramo samo razred za u\u010denje (RandomizedLearner), za napovedovanje s povpre\u010denjem napovedi ve\u010dih modelov pa recikliramo kar BaggedModel. RandomizedLearner je podobno preprost kot BaggedLearner. Za izbor atributov oziroma konstrukcijo nove tabele z podmno\u017eico originalnih atributov smo uporabili kar Orange-ov SelectRandomFeatures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RandomizedLearner(Orange.classification.Learner):\n",
      "    \"\"\"Ensamble learning through randomization of data domain.\"\"\"\n",
      "    def __init__(self, learner, k=3, p=0.1):\n",
      "        super().__init__()\n",
      "        self.k = k\n",
      "        self.learner = learner\n",
      "        self.name = \"rand \" + self.learner.name\n",
      "        # a function to be used for random attribute subset selection\n",
      "        self.selector = Orange.preprocess.fss.SelectRandomFeatures(k=p)\n",
      "    \n",
      "    def fit_storage(self, data):\n",
      "        \"\"\"Returns a bagged model with randomized regressors.\"\"\"\n",
      "        models = []\n",
      "        for epoch in range(self.k):\n",
      "            sample = self.selector(data) # data with a subset of attributes\n",
      "            models.append(self.learner(sample))\n",
      "        model = BaggedModel(data.domain, models)\n",
      "        model.name = self.name\n",
      "        return model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rnd_lr = RandomizedLearner(lr, k=50)\n",
      "learners = [mean, lr, rnd_lr]\n",
      "res = Orange.evaluation.CrossValidation(data, learners, k=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.RMSE(res))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                mean 24.73\n",
        "               ridge 34.80\n",
        "          rand ridge 19.54\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tole deluje prav presenetljivo dobro (primerjaj zadnjo in predzadnjo vrstico). Linearna regresija z L2 regularizacijo na tej domeni, ki ima veliko \u0161tevilo atributov, ne deluje prav dobro. Tu smo seveda pozabili na optimizacijo stopnje regulatizacije, s katero bi prav gotovo lahko \u0161e kaj pridobili. A tudi taka metoda, po tem, ko jo uporabimo za u\u010denje ansambla na zmanj\u0161anjih in atributno-vzor\u010denih domenah do\u017eivi svoj preprod."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Naklju\u010dni gozd"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Klasi\u010den, ali celo najbolj tipi\u010den primer ponaklu\u010denja (randomizacije) so naklju\u010dni gozdovi (angl. random forest). Tu je bil narejen poseg v algoritem u\u010denja dreves, ki ob gradnji drevesa ne uporabi va\u010d za razcep mno\u017eice primerov najprimernej\u0161ega atributa, ampak atribut za razcep naklju\u010dno izbere iz mno\u017eice najprimernej\u0161i. Poleg uporabljenega vzor\u010danje z metodo stremena to \u0161e dodatno poskrbi za raznolikost dreves v gozdu.\n",
      "\n",
      "Spodaj smo kot primer uporabili kar SimpleRandomForestLearner, ki je hitra C-jevska implementacija naklju\u010dnih gozdov. Ugibam, da je ta implementacija morda najhitrej\u0161a implementacija naklju\u010dnega gozda z vmesnikom v Pythonu. Orange zawrapa sicer tudi implementacijo iz sklearn-a (RandomForestLearner), ki pa meni, vsaj na tej domeni, presenetljivo ne deluje dobro in je veliko po\u010dasnej\u0161a od Juretove implementacije. [morda je za vse skupaj kriv kak\u0161en bug, \u010de ga kdo najde, naj mi sporo\u010di]."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skl_forest = Orange.classification.RandomForestLearner(n_estimators=50)\n",
      "skl_forest.name = \"skl forest\"\n",
      "forest = Orange.classification.SimpleRandomForestLearner(n_estimators=50)\n",
      "learners = [tree, forest, skl_forest, elastic, rnd_lr]\n",
      "res = Orange.evaluation.CrossValidation(data, learners, k=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"\\n\".join(\"%20s %5.2f\" % (learner.name, score) for learner, score in zip(learners, Orange.evaluation.RMSE(res))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         simple tree 24.03\n",
        "           simple rf 18.90\n",
        "          skl forest 26.36\n",
        "             elastic 19.66\n",
        "          rand ridge 19.68\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}